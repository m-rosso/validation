{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation procedures\n",
    "## Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This projects conducted to the development of classes that have the goal of contributing with validation procedures during the implementation of data modeling in supervised learning tasks. This tutorial has the goal of showing its easy use and flexibility.\n",
    "<br>\n",
    "<br>\n",
    "Use cases for the classes presented here are as follows:\n",
    "* *KfoldsCV*, for perfoming grid/random search of a Light GBM model.\n",
    "* *KfoldsCV_fit*, for performing grid/random search and fitting a SVM classifier using the entire training data and the best choices of hyper-parameters. Besides, the same for GBM classifier is applied together with parallelization for reducing overall running time.\n",
    "* *bootstrap_estimation*, for running a large collection of estimations in order to assess average and standard deviation of performance metrics, using a regularized logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All estimations have no intention of being as efficient as possibile, but focus on illustrating how those classes can be used in real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook imports the developed classes in addition to a data pre-processing pipeline that seeks to assess their functionalities by applying several distinct statistical learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "1. [Libraries](#libraries)<a href='#libraries'></a>.\n",
    "2. [Functions and classes](#functions_classes)<a href='#functions_classes'></a>.\n",
    "3. [Settings](#settings)<a href='#settings'></a>.\n",
    "4. [Importing datasets](#imports)<a href='#imports'></a>.\n",
    "5. [Data pre-processing](#data_pre_proc)<a href='#data_pre_proc'></a>.\n",
    "6. [Assessing K-folds CV](#kfolds_assess)<a href='#kfolds_assess'></a>.\n",
    "    * [Light GBM](#kfolds_light_gbm)<a href='#kfolds_light_gbm'></a>.\n",
    "<br>\n",
    "<br>\n",
    "7. [Assessing K-folds fit](#kfolds_fit_assess)<a href='#kfolds_fit_assess'></a>.\n",
    "    * [SVM classifier](#kfolds_fit_svm_class)<a href='#kfolds_fit_svm_class'></a>.\n",
    "    * [Parallel estimation (GBM)](#kfolds_fit_gbm_parallel)<a href='#kfolds_fit_gbm_parallel'></a>.\n",
    "<br>\n",
    "<br>\n",
    "8. [Assessing bootstrap estimation](#boot_assess)<a href='#boot_assess'></a>.\n",
    "    * [Logistic regression](#boot_lr)<a href='#boot_lr'></a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='libraries'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import progressbar\n",
    "\n",
    "from scipy.stats import uniform, norm, randint\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, auc, precision_recall_curve, brier_score_loss\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# pip install lightgbm\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='functions_classes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import loading_data, classify_features, assessing_missings\n",
    "from utils import data_consistency, running_time, missings_detection, frequency_list, cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformations\n",
    "from transformations import log_transformation, standard_scale, impute_missing, one_hot_encoding\n",
    "from transformations import applying_log_transf, applying_standard_scale, treating_missings, applying_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfolds\n",
    "from kfolds import KfoldsCV, Kfolds_fit\n",
    "\n",
    "import bootstrap\n",
    "from bootstrap import bootstrap_estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='settings'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare whether to export results:\n",
    "export = True\n",
    "\n",
    "# Declare whether to log-transform numerical features:\n",
    "log_transform = True\n",
    "\n",
    "# Declare whether to standardize numerical features:\n",
    "standardize = True\n",
    "\n",
    "# Define the dataset_id:\n",
    "dataset_id = 2706"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feats_label'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\u001b[1mStore 2706:\u001b[0m\n",
      "Shape of df: (14434, 2628).\n",
      "Number of distinct instances: 14434.\n",
      "Time period: from 2020-12-31 to 2021-03-31.\n",
      "----------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVGITEMCREATIONTIME()</th>\n",
       "      <th>BILLINGADDRESSCHARRANDOMNESS()</th>\n",
       "      <th>BILLINGADDRESSCHARWORDMODELPROB()</th>\n",
       "      <th>BILLINGADDRESSRANDOMNESS()</th>\n",
       "      <th>BILLINGCITY()</th>\n",
       "      <th>BILLINGCOUNTRY()</th>\n",
       "      <th>BILLINGLARGEAREAREPUTATION()</th>\n",
       "      <th>BILLINGNAMECHARRANDOMNESS()</th>\n",
       "      <th>BILLINGNAMECHARWORDMODELPROB()</th>\n",
       "      <th>BILLINGNAMERANDOMNESS()</th>\n",
       "      <th>...</th>\n",
       "      <th>ZIPFIRST3REPUTATION()</th>\n",
       "      <th>ZIPFIRST5REPUTATION()</th>\n",
       "      <th>y</th>\n",
       "      <th>order_amount</th>\n",
       "      <th>order_id</th>\n",
       "      <th>status</th>\n",
       "      <th>epoch</th>\n",
       "      <th>store_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255415</td>\n",
       "      <td>0.194991</td>\n",
       "      <td>9.357623e-14</td>\n",
       "      <td>Venustiano carranza</td>\n",
       "      <td>MX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983040</td>\n",
       "      <td>0.034951</td>\n",
       "      <td>7.736941e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061190</td>\n",
       "      <td>0.045009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1795.16</td>\n",
       "      <td>130874044224</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1609459270000.0</td>\n",
       "      <td>2706</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-31 21:01:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.299488</td>\n",
       "      <td>0.117108</td>\n",
       "      <td>9.357623e-14</td>\n",
       "      <td>Coacalco de berriozabal</td>\n",
       "      <td>MX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.351049</td>\n",
       "      <td>0.097665</td>\n",
       "      <td>2.301321e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091155</td>\n",
       "      <td>0.078335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4092.23</td>\n",
       "      <td>130874049768</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1609459766000.0</td>\n",
       "      <td>2706</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-31 21:09:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.201846</td>\n",
       "      <td>0.204315</td>\n",
       "      <td>9.357623e-14</td>\n",
       "      <td>Hermosillo</td>\n",
       "      <td>MX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189533</td>\n",
       "      <td>0.180326</td>\n",
       "      <td>9.357623e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.118511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1871.40</td>\n",
       "      <td>130874053609</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1609460116000.0</td>\n",
       "      <td>2706</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-31 21:15:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2628 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AVGITEMCREATIONTIME()  BILLINGADDRESSCHARRANDOMNESS()  \\\n",
       "0                    NaN                        0.255415   \n",
       "1                    NaN                        0.299488   \n",
       "2                    NaN                        0.201846   \n",
       "\n",
       "   BILLINGADDRESSCHARWORDMODELPROB()  BILLINGADDRESSRANDOMNESS()  \\\n",
       "0                           0.194991                9.357623e-14   \n",
       "1                           0.117108                9.357623e-14   \n",
       "2                           0.204315                9.357623e-14   \n",
       "\n",
       "             BILLINGCITY() BILLINGCOUNTRY()  BILLINGLARGEAREAREPUTATION()  \\\n",
       "0      Venustiano carranza               MX                           NaN   \n",
       "1  Coacalco de berriozabal               MX                           NaN   \n",
       "2               Hermosillo               MX                           NaN   \n",
       "\n",
       "   BILLINGNAMECHARRANDOMNESS()  BILLINGNAMECHARWORDMODELPROB()  \\\n",
       "0                     0.983040                        0.034951   \n",
       "1                     0.351049                        0.097665   \n",
       "2                     0.189533                        0.180326   \n",
       "\n",
       "   BILLINGNAMERANDOMNESS()  ...  ZIPFIRST3REPUTATION() ZIPFIRST5REPUTATION()  \\\n",
       "0             7.736941e-01  ...               0.061190              0.045009   \n",
       "1             2.301321e-09  ...               0.091155              0.078335   \n",
       "2             9.357623e-14  ...               0.069444              0.118511   \n",
       "\n",
       "     y  order_amount      order_id    status            epoch  store_id  \\\n",
       "0  0.0       1795.16  130874044224  APPROVED  1609459270000.0      2706   \n",
       "1  0.0       4092.23  130874049768  APPROVED  1609459766000.0      2706   \n",
       "2  0.0       1871.40  130874053609  APPROVED  1609460116000.0      2706   \n",
       "\n",
       "   weight                date  \n",
       "0     1.0 2020-12-31 21:01:10  \n",
       "1     1.0 2020-12-31 21:09:26  \n",
       "2     1.0 2020-12-31 21:15:16  \n",
       "\n",
       "[3 rows x 2628 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('----------------------------------------')\n",
    "print(f'\\033[1mStore {dataset_id}:\\033[0m')\n",
    "\n",
    "df_train = loading_data(path=f'../data_pipeline/Datasets/dataset_{dataset_id}.csv',\n",
    "                        dtype={'order_id': str, 'store_id': int, 'epoch': str},\n",
    "                        id_var='order_id')\n",
    "\n",
    "print('----------------------------------------')\n",
    "print('\\n')\n",
    "\n",
    "# Accessory variables:\n",
    "drop_vars = ['y', 'order_amount', 'store_id', 'order_id', 'status', 'epoch', 'date', 'weight']\n",
    "\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df_train['train_test'] = 'test'\n",
    "df_train['train_test'].iloc[:int(df_train.shape[0]/2)] = 'train'\n",
    "\n",
    "# Train-test split:\n",
    "df_test = df_train[df_train.train_test == 'test'].copy()\n",
    "df_train = df_train[df_train.train_test == 'train'].copy()\n",
    "\n",
    "# Resetting indices:\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "drop_vars.append('train_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classif_feat'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset 2706:\u001b[0m\n",
      "Initial number of features: 2620.\n",
      "1377 features were dropped for excessive number of missings!\n",
      "300 features were dropped for having no variance!\n",
      "943 remaining features.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>cont_vars</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cat_vars</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>binary_vars</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>drop_vars</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class  frequency\n",
       "2    cont_vars        915\n",
       "0     cat_vars         14\n",
       "1  binary_vars         14\n",
       "3    drop_vars          9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'\\033[1mDataset {dataset_id}:\\033[0m')\n",
    "classified_features = classify_features(df_train, drop_vars=drop_vars,\n",
    "                                        drop_excessive_miss=True, drop_no_var=True,\n",
    "                                        test_data=df_test)\n",
    "\n",
    "feats_assess = classified_features['feats_assess']\n",
    "cat_vars = classified_features['cat_vars']\n",
    "excessive_miss_train = classified_features['excessive_miss_train']\n",
    "no_variance = classified_features['no_variance']\n",
    "cont_vars = classified_features['cont_vars']\n",
    "binary_vars = classified_features['binary_vars']\n",
    "    \n",
    "feats_assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_pre_proc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessing_missing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset 2706:\u001b[0m\n",
      "\u001b[1mTraining data:\u001b[0m\n",
      "\u001b[1mNumber of features with missings:\u001b[0m 231 out of 952 features (24.26%).\n",
      "\u001b[1mAverage number of missings:\u001b[0m 478 out of 7217 observations (6.62%).\n",
      "\n",
      "\u001b[1mTest data:\u001b[0m\n",
      "\u001b[1mNumber of features with missings:\u001b[0m 134 out of 952 features (14.08%).\n",
      "\u001b[1mAverage number of missings:\u001b[0m 470 out of 7217 observations (6.51%).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>missings</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CUSTNAVCOUNT(t,30min)</td>\n",
       "      <td>6772</td>\n",
       "      <td>0.938340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CUSTNAVCOUNT(t,1h)</td>\n",
       "      <td>6751</td>\n",
       "      <td>0.935430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CUSTNAVCOUNT(9,30min)</td>\n",
       "      <td>6743</td>\n",
       "      <td>0.934322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CUSTNAVENTROPY(COOKIE)</td>\n",
       "      <td>6737</td>\n",
       "      <td>0.933490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CUSTNAVCOUNT(9,1h)</td>\n",
       "      <td>6713</td>\n",
       "      <td>0.930165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>CUSTNAVCOUNT(t,1d)</td>\n",
       "      <td>6691</td>\n",
       "      <td>0.927117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>CUSTNAVCOUNT(ta,30min)</td>\n",
       "      <td>6683</td>\n",
       "      <td>0.926008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>CUSTNAVCOUNT(ta,1h)</td>\n",
       "      <td>6655</td>\n",
       "      <td>0.922128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>CREDITCARD(TOTAL_AMOUNT,60)</td>\n",
       "      <td>6604</td>\n",
       "      <td>0.915062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>EMAIL(TOTAL_AMOUNT,60)</td>\n",
       "      <td>6524</td>\n",
       "      <td>0.903977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   feature  missings     share\n",
       "training_data                                                 \n",
       "0                    CUSTNAVCOUNT(t,30min)      6772  0.938340\n",
       "1                       CUSTNAVCOUNT(t,1h)      6751  0.935430\n",
       "2                    CUSTNAVCOUNT(9,30min)      6743  0.934322\n",
       "3                   CUSTNAVENTROPY(COOKIE)      6737  0.933490\n",
       "4                       CUSTNAVCOUNT(9,1h)      6713  0.930165\n",
       "5                       CUSTNAVCOUNT(t,1d)      6691  0.927117\n",
       "6                   CUSTNAVCOUNT(ta,30min)      6683  0.926008\n",
       "7                      CUSTNAVCOUNT(ta,1h)      6655  0.922128\n",
       "8              CREDITCARD(TOTAL_AMOUNT,60)      6604  0.915062\n",
       "9                   EMAIL(TOTAL_AMOUNT,60)      6524  0.903977"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'\\033[1mDataset {dataset_id}:\\033[0m')\n",
    "print('\\033[1mTraining data:\\033[0m')\n",
    "missings_train = assessing_missings(dataframe=df_train)\n",
    "print('\\n\\033[1mTest data:\\033[0m')\n",
    "missings_test = assessing_missings(dataframe=df_test)\n",
    "print('\\n')\n",
    "\n",
    "missings_train.index.name = 'training_data'\n",
    "missings_test.index.name = 'test_data'\n",
    "\n",
    "missings_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='num_transf'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logarithmic transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mAPPLYING LOGARITHMIC TRANSFORMATION OVER NUMERICAL DATA\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mDataset 2706:\u001b[0m\n",
      "\u001b[1mTraining data:\u001b[0m\n",
      "\u001b[1mNumber of numerical variables log-transformed:\u001b[0m 915.\n",
      "\u001b[1mTest data:\u001b[0m\n",
      "\u001b[1mNumber of numerical variables log-transformed:\u001b[0m 915.\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\033[1mAPPLYING LOGARITHMIC TRANSFORMATION OVER NUMERICAL DATA\\033[0m')\n",
    "print('\\n')\n",
    "\n",
    "print(f'\\033[1mDataset {dataset_id}:\\033[0m')\n",
    "\n",
    "# Variables that should not be log-transformed:\n",
    "not_log = [c for c in df_train.columns if c not in cont_vars]\n",
    "\n",
    "if log_transform:\n",
    "    print('\\033[1mTraining data:\\033[0m')\n",
    "    df_train = applying_log_transf(dataframe=df_train, not_log=not_log)\n",
    "\n",
    "    print('\\033[1mTest data:\\033[0m')\n",
    "    df_test = applying_log_transf(dataframe=df_test, not_log=not_log)\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "else:\n",
    "    print('\\033[1mNo transformation performed!\\033[0m')\n",
    "    print('\\n')\n",
    "\n",
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mAPPLYING STANDARD SCALE TRANSFORMATION OVER NUMERICAL DATA\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mDataset 2706:\u001b[0m\n",
      "\u001b[1mStandard scaling training data...\u001b[0m\n",
      "\u001b[1mStandard scaling test data...\u001b[0m\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\033[1mAPPLYING STANDARD SCALE TRANSFORMATION OVER NUMERICAL DATA\\033[0m')\n",
    "print('\\n')\n",
    "\n",
    "print(f'\\033[1mDataset {dataset_id}:\\033[0m')\n",
    "\n",
    "# Inputs that should not be standardized:\n",
    "not_stand = [c for c in df_train.columns if c.replace('L#', '') not in cont_vars]\n",
    "\n",
    "if standardize:\n",
    "    scaled_data = applying_standard_scale(training_data=df_train, not_stand=not_stand,\n",
    "                                          test_data=df_test)\n",
    "    df_train_scaled = scaled_data['training_data']\n",
    "    df_test_scaled = scaled_data['test_data']\n",
    "\n",
    "else:\n",
    "    df_train_scaled = df_train.copy()\n",
    "    df_test_scaled = df_test.copy()\n",
    "\n",
    "    print('\\033[1mNo transformation performed!\\033[0m')\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mTREATING MISSING VALUES\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mDataset 2706:\u001b[0m\n",
      "\u001b[1mTreating missing values of training data...\u001b[0m\n",
      "\u001b[1mTreating missing values of test data...\u001b[0m\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\033[1mTREATING MISSING VALUES\\033[0m')\n",
    "print('\\n')\n",
    "\n",
    "print(f'\\033[1mDataset {dataset_id}:\\033[0m')\n",
    "\n",
    "print('\\033[1mTreating missing values of training data...\\033[0m')\n",
    "df_train_scaled = treating_missings(dataframe=df_train_scaled, cat_vars=cat_vars,\n",
    "                                    drop_vars=drop_vars)\n",
    "\n",
    "print('\\033[1mTreating missing values of test data...\\033[0m')\n",
    "df_test_scaled = treating_missings(dataframe=df_test_scaled, cat_vars=cat_vars,\n",
    "                                   drop_vars=drop_vars)\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical_transf'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dummies through one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset 2706:\u001b[0m\n",
      "\u001b[1mNumber of categorical features:\u001b[0m 14\n",
      "\u001b[1mNumber of overall selected dummies:\u001b[0m 126.\n",
      "\u001b[1mShape of df_train_scaled:\u001b[0m (7217, 1291).\n",
      "\u001b[1mShape of df_test_scaled:\u001b[0m (7217, 1194).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\033[1mDataset {dataset_id}:\\033[0m')\n",
    "\n",
    "transf_data = applying_one_hot(df_train_scaled, cat_vars, test_data=df_test_scaled)\n",
    "df_train_scaled = transf_data['training_data']\n",
    "df_test_scaled = transf_data['test_data']\n",
    "\n",
    "print(f'\\033[1mShape of df_train_scaled:\\033[0m {df_train_scaled.shape}.')\n",
    "print(f'\\033[1mShape of df_test_scaled:\\033[0m {df_test_scaled.shape}.')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del transf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing missing values (training data):\n",
    "missings_detection(df_train_scaled, name=f'df_train_scaled (dataset {dataset_id})')\n",
    "\n",
    "# Assessing missing values (test data):\n",
    "missings_detection(df_test_scaled, name=f'df_test_scaled (dataset {dataset_id})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='datasets_structure'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset 2706\u001b[0m:\n",
      "Training and test data are consistent with each other.\n"
     ]
    }
   ],
   "source": [
    "print(f'\\033[1mDataset {dataset_id}\\033[0m:')\n",
    "df_test_scaled = data_consistency(dataframe=df_train_scaled,\n",
    "                                  test_data=df_test_scaled)['test_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kfolds_assess'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing K-folds CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kfolds_light_gbm'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click [here](https://lightgbm.readthedocs.io/en/latest/index.html) for documentation of light GBM library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[1mGrid estimation progress:\u001b[0m [                                              ] N/A%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mGrid estimation progress:\u001b[0m [----                                          ]  10%/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[1mGrid estimation progress:\u001b[0m [---------                                     ]  20%/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mGrid estimation progress:\u001b[0m [-------------                                 ]  30%/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[1mGrid estimation progress:\u001b[0m [------------------                            ]  40%/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mGrid estimation progress:\u001b[0m [-----------------------                       ]  50%/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mGrid estimation progress:\u001b[0m [---------------------------                   ]  60%/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mGrid estimation progress:\u001b[0m [--------------------------------              ]  70%/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mGrid estimation progress:\u001b[0m [------------------------------------          ]  80%/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[1mGrid estimation progress:\u001b[0m [-----------------------------------------     ]  90%/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[1mGrid estimation progress:\u001b[0m [----------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "\u001b[1mK-folds CV outcomes:\u001b[0m\n",
      "Number of data folds: 3.\n",
      "Number of samples for random search: 10.\n",
      "Estimation method: light gbm.\n",
      "Metric for choosing best hyper-parameter: roc_auc.\n",
      "Best hyper-parameters: {'bagging_fraction': 0.8564267514042088, 'learning_rate': 0.03307956006799815, 'max_depth': 5, 'num_iterations': 250}.\n",
      "CV performance metric associated with best hyper-parameters: 0.9818.\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\u001b[1mRunning time:\u001b[0m 1.07 minutes.\n",
      "Start time: 2021-05-18, 17:28:52\n",
      "End time: 2021-05-18, 17:29:56\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Grid of hyper-parameters:\n",
    "grid_param = {'bagging_fraction': uniform(0.5, 0.5),\n",
    "              'learning_rate': uniform(0.0001, 0.1),\n",
    "              'max_depth': randint(1, 10),\n",
    "              'num_iterations': [100, 250, 500]}\n",
    "\n",
    "# Creating K-folds CV object:\n",
    "kfolds = KfoldsCV(task = 'binary', method = 'light_gbm', num_folds = 3, metric = 'roc_auc',\n",
    "                  random_search = True, n_samples = 10,\n",
    "                  grid_param = grid_param,\n",
    "                  default_param = {'bagging_fraction': 0.75,\n",
    "                                   'learning_rate': 0.01,\n",
    "                                   'max_depth': 10,\n",
    "                                   'num_iterations': 500},\n",
    "                  cost_function='cross_entropy')\n",
    "\n",
    "# Running K-folds CV:\n",
    "kfolds.run(inputs = df_train_scaled.drop(drop_vars, axis=1), output = df_train_scaled['y'])\n",
    "\n",
    "# Defining best tuning hyper-parameter:\n",
    "best_param = kfolds.best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.8564267514042088,\n",
       " 'learning_rate': 0.03307956006799815,\n",
       " 'max_depth': 5,\n",
       " 'num_iterations': 250}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best tuning hyper-parameters:\n",
    "kfolds.best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row0_col0 {\n",
       "            width:  300px;\n",
       "        }    #T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row1_col0 {\n",
       "            width:  300px;\n",
       "        }    #T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row2_col0 {\n",
       "            width:  300px;\n",
       "        }    #T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row3_col0 {\n",
       "            width:  300px;\n",
       "        }    #T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row4_col0 {\n",
       "            width:  300px;\n",
       "        }    #T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row5_col0 {\n",
       "            width:  300px;\n",
       "        }    #T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row6_col0 {\n",
       "            width:  300px;\n",
       "        }    #T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row7_col0 {\n",
       "            width:  300px;\n",
       "        }    #T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row8_col0 {\n",
       "            width:  300px;\n",
       "        }    #T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row9_col0 {\n",
       "            width:  300px;\n",
       "        }</style><table id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >tun_param</th>        <th class=\"col_heading level0 col1\" >cv_roc_auc</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row0_col0\" class=\"data row0 col0\" >{'bagging_fraction': 0.8564267514042088, 'learning_rate': 0.03307956006799815, 'max_depth': 5, 'num_iterations': 250}</td>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row0_col1\" class=\"data row0 col1\" >0.981832</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row1_col0\" class=\"data row1 col0\" >{'bagging_fraction': 0.6598188679693455, 'learning_rate': 0.06896039726050547, 'max_depth': 8, 'num_iterations': 500}</td>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row1_col1\" class=\"data row1 col1\" >0.980826</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1level0_row2\" class=\"row_heading level0 row2\" >8</th>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row2_col0\" class=\"data row2 col0\" >{'bagging_fraction': 0.8907666526719143, 'learning_rate': 0.06191495909029268, 'max_depth': 3, 'num_iterations': 100}</td>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row2_col1\" class=\"data row2 col1\" >0.980798</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1level0_row3\" class=\"row_heading level0 row3\" >6</th>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row3_col0\" class=\"data row3 col0\" >{'bagging_fraction': 0.9430910631497579, 'learning_rate': 0.04818394450453028, 'max_depth': 8, 'num_iterations': 500}</td>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row3_col1\" class=\"data row3 col1\" >0.980569</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1level0_row4\" class=\"row_heading level0 row4\" >9</th>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row4_col0\" class=\"data row4 col0\" >{'bagging_fraction': 0.9163785959047468, 'learning_rate': 0.09387259961233586, 'max_depth': 6, 'num_iterations': 500}</td>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row4_col1\" class=\"data row4 col1\" >0.980061</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row5_col0\" class=\"data row5 col0\" >{'bagging_fraction': 0.7198296782892253, 'learning_rate': 0.03495206821405517, 'max_depth': 5, 'num_iterations': 100}</td>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row5_col1\" class=\"data row5 col1\" >0.978563</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1level0_row6\" class=\"row_heading level0 row6\" >1</th>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row6_col0\" class=\"data row6 col0\" >{'bagging_fraction': 0.6188968287608833, 'learning_rate': 0.05093991681484368, 'max_depth': 1, 'num_iterations': 500}</td>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row6_col1\" class=\"data row6 col1\" >0.97797</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1level0_row7\" class=\"row_heading level0 row7\" >4</th>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row7_col0\" class=\"data row7 col0\" >{'bagging_fraction': 0.9045568719088195, 'learning_rate': 0.02091435858274271, 'max_depth': 7, 'num_iterations': 100}</td>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row7_col1\" class=\"data row7 col1\" >0.974292</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1level0_row8\" class=\"row_heading level0 row8\" >3</th>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row8_col0\" class=\"data row8 col0\" >{'bagging_fraction': 0.536585497553552, 'learning_rate': 0.04616855762740995, 'max_depth': 1, 'num_iterations': 100}</td>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row8_col1\" class=\"data row8 col1\" >0.970582</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1level0_row9\" class=\"row_heading level0 row9\" >7</th>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row9_col0\" class=\"data row9 col0\" >{'bagging_fraction': 0.5267165018530952, 'learning_rate': 0.005129053997969813, 'max_depth': 8, 'num_iterations': 100}</td>\n",
       "                        <td id=\"T_cfb32c34_b817_11eb_98cd_4b74bcfac3e1row9_col1\" class=\"data row9 col1\" >0.958813</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f0c6b063bd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV metrics:\n",
    "kfolds.CV_metric.sort_values('cv_roc_auc',\n",
    "                             ascending=False).style.set_properties(subset=['tun_param'], **{'width': '300px'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kfolds_fit_assess'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing K-folds fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kfolds_fit_svm_class'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mGrid estimation progress:\u001b[0m [----------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "\u001b[1mTrain-test estimation outcomes:\u001b[0m\n",
      "\n",
      "\n",
      "Outcomes from K-folds CV estimation:\n",
      "   Number of data folds: 3.\n",
      "   Estimation method: SVM.\n",
      "   Metric for choosing best hyper-parameter: roc_auc.\n",
      "   Best hyper-parameters: {'C': '1', 'kernel': 'poly', 'degree': '1', 'gamma': 'scale'}.\n",
      "   CV performance metric associated with best hyper-parameters: 0.9639.\n",
      "\n",
      "\n",
      "Performance metrics evaluated at test data:\n",
      "   test_roc_auc = 0.9833\n",
      "   test_prec_avg = 0.9237\n",
      "   test_brier = 0.009\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\u001b[1mRunning time:\u001b[0m 4.49 minutes.\n",
      "Start time: 2021-05-18, 17:29:57\n",
      "End time: 2021-05-18, 17:34:26\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Declare grid of hyper-parameters:\n",
    "params = {'C': [1],\n",
    "          'kernel': ['poly'],\n",
    "          'degree': [1, 2, 3, 4],\n",
    "          'gamma': ['scale']}\n",
    "params_default = {'C': 1.0, 'kernel': 'poly', 'degree': 1, 'gamma': 'scale'}\n",
    "\n",
    "# Declare K-folds CV estimation object:\n",
    "kfolds = Kfolds_fit(task='classification', method='SVM',\n",
    "                    metric='roc_auc', num_folds=3, pre_selecting=False, random_search=False,\n",
    "                    grid_param=params, default_param=params_default)\n",
    "\n",
    "# Running train-test estimation:\n",
    "kfolds.fit(train_inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "           train_output=df_train_scaled['y'],\n",
    "           test_inputs=df_test_scaled.drop(drop_vars, axis=1),\n",
    "           test_output=df_test_scaled['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kfolds_fit_gbm_parallel'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel estimation (GBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential train-validation estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mGrid estimation progress:\u001b[0m [----------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "\u001b[1mTrain-test estimation outcomes:\u001b[0m\n",
      "\n",
      "\n",
      "Outcomes from K-folds CV estimation:\n",
      "   Number of data folds: 3.\n",
      "   Estimation method: GBM.\n",
      "   Metric for choosing best hyper-parameter: roc_auc.\n",
      "   Best hyper-parameters: {'subsample': 0.75, 'learning_rate': 0.01, 'max_depth': 5.0, 'n_estimators': 500.0}.\n",
      "   CV performance metric associated with best hyper-parameters: 0.9592.\n",
      "\n",
      "\n",
      "Performance metrics evaluated at test data:\n",
      "   test_roc_auc = 0.9918\n",
      "   test_prec_avg = 0.9505\n",
      "   test_brier = 0.0044\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\u001b[1mRunning time:\u001b[0m 31.08 minutes.\n",
      "Start time: 2021-06-04, 21:12:51\n",
      "End time: 2021-06-04, 21:43:56\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Declare grid of hyper-parameters:\n",
    "params = {'subsample': 0.75,\n",
    "          'learning_rate': [0.0001, 0.001, 0.01],\n",
    "          'max_depth': [1, 3, 5],\n",
    "          'n_estimators': 500}\n",
    "params_default = {'subsample': 0.75,\n",
    "                  'learning_rate': 0.01,\n",
    "                  'max_depth': 10,\n",
    "                  'n_estimators': 500}\n",
    "\n",
    "# Declare K-folds CV estimation object:\n",
    "train_test_est = Kfolds_fit(task='classification', method='GBM',\n",
    "                            metric='roc_auc', num_folds=3, pre_selecting=False,\n",
    "                            random_search=False, grid_param=params, default_param=params_default,\n",
    "                            parallelize=False)\n",
    "\n",
    "# Running train-test estimation:\n",
    "train_test_est.fit(train_inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                   train_output=df_train_scaled['y'],\n",
    "                   test_inputs=df_test_scaled.drop(drop_vars, axis=1),\n",
    "                   test_output=df_test_scaled['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel train-validation estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mGrid estimation progress:\u001b[0m [----------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "\u001b[1mTrain-test estimation outcomes:\u001b[0m\n",
      "\n",
      "\n",
      "Outcomes from K-folds CV estimation:\n",
      "   Number of data folds: 3.\n",
      "   Estimation method: GBM.\n",
      "   Metric for choosing best hyper-parameter: roc_auc.\n",
      "   Best hyper-parameters: {'subsample': 0.75, 'learning_rate': 0.01, 'max_depth': 3.0, 'n_estimators': 500.0}.\n",
      "   CV performance metric associated with best hyper-parameters: 0.9592.\n",
      "\n",
      "\n",
      "Performance metrics evaluated at test data:\n",
      "   test_roc_auc = 0.9875\n",
      "   test_prec_avg = 0.9504\n",
      "   test_brier = 0.0043\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\u001b[1mRunning time:\u001b[0m 12.93 minutes.\n",
      "Start time: 2021-06-04, 21:43:56\n",
      "End time: 2021-06-04, 21:56:52\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Declare grid of hyper-parameters:\n",
    "params = {'subsample': 0.75,\n",
    "          'learning_rate': [0.0001, 0.001, 0.01],\n",
    "          'max_depth': [1, 3, 5],\n",
    "          'n_estimators': 500}\n",
    "params_default = {'subsample': 0.75,\n",
    "                  'learning_rate': 0.01,\n",
    "                  'max_depth': 10,\n",
    "                  'n_estimators': 500}\n",
    "\n",
    "# Declare K-folds CV estimation object:\n",
    "train_test_est = Kfolds_fit(task='classification', method='GBM',\n",
    "                            metric='roc_auc', num_folds=3, pre_selecting=False,\n",
    "                            random_search=False, grid_param=params, default_param=params_default,\n",
    "                            parallelize=True)\n",
    "\n",
    "# Running train-test estimation:\n",
    "train_test_est.fit(train_inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                   train_output=df_train_scaled['y'],\n",
    "                   test_inputs=df_test_scaled.drop(drop_vars, axis=1),\n",
    "                   test_output=df_test_scaled['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='boot_assess'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing bootstrap estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='boot_lr'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBoostrap estimation progress: \u001b[0m[==========================================] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------\n",
      "\u001b[1mBootstrap statistics:\u001b[0m\n",
      "   Number of estimations: 1000.\n",
      "   avg(roc_auc) = 0.984\n",
      "   std(roc_auc) = 0.0017\n",
      "   avg(prec_avg) = 0.9237\n",
      "   std(prec_avg) = 0.0048\n",
      "   avg(brier) = 0.0095\n",
      "   std(brier) = 0.0004\n",
      "\n",
      "\n",
      "\u001b[1m   Performance metrics based on bootstrap scores:\u001b[0m\n",
      "   roc_auc = 0.9863\n",
      "   prec_avg = 0.9333\n",
      "   brier = 0.0088\n",
      "   Hyper-parameters used in estimations: {'C': 0.1}.\n",
      "---------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\u001b[1mRunning time:\u001b[0m 18.08 minutes.\n",
      "Start time: 2021-05-18, 17:34:27\n",
      "End time: 2021-05-18, 17:52:31\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Declare grid of hyper-parameters:\n",
    "params_default = {'C': 0.1}\n",
    "\n",
    "# Declare bootstrap estimation object:\n",
    "boot_estimations = bootstrap_estimation(task='classification', method='logistic_regression',\n",
    "                                        metric='roc_auc', num_folds=3, pre_selecting=False, random_search=False,\n",
    "                                        grid_param=params, default_param=params_default,\n",
    "                                        cv=False, replacement=True, n_iterations=1000, bootstrap_scores=True)\n",
    "\n",
    "# Running bootstrap estimation:\n",
    "boot_estimations.run(train_inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                     train_output=df_train_scaled['y'],\n",
    "                     test_inputs=df_test_scaled.drop(drop_vars, axis=1),\n",
    "                     test_output=df_test_scaled['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
